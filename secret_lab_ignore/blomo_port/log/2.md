(.venv) PS F:\Development\superintelligence> python secret_lab_ignore/blomo_port/lab.py --module 2
Loading Bolmo-1B on cpu (dtype=torch.float32)...
Loading weights: 100%|█| 263/263 [00:00<00:00, 2395.36it/s, Materializing param=model.n
Loaded. Parameters: 1,468,911,776

--- Module 2: Build boundary_adaptor.npz ---
Loaded boundary scores from cache (F:\Development\superintelligence\data\cache\blomo_port\69eb4607b69f0909)
Bolmo boundary score statistics:
  mean: 0.9148
  std: 0.2476
  min: 0.0005
  max: 1.0000
  median: 0.9994
  q25: 0.9974
  q75: 0.9998
  rate_gt_0p5: 0.9137

Exported boundary_adaptor.npz -> F:\Development\superintelligence\data\cache\blomo_port\analysis\boundary_adaptor.npz
frac_residual: 0.573042
  K=2048: residual R2=0.554306  full-logit R2=0.744598
  K=4096: residual R2=0.643910  full-logit R2=0.795945
  K=8192: residual R2=0.748704  full-logit R2=0.855997
  K=16384: residual R2=0.865966  full-logit R2=0.923193
  K=32768: residual R2=0.967106  full-logit R2=0.981150

Done.
(.venv) PS F:\Development\superintelligence> python secret_lab_ignore/blomo_port/lab.py --module 3
Loading Bolmo-1B on cpu (dtype=torch.float32)...
Loading weights: 100%|█| 263/263 [00:00<00:00, 2125.61it/s, Materializing param=model.n
Loaded. Parameters: 1,468,911,776

--- Module 3: Prefill boundary eval (adaptor vs Bolmo) ---

K=2048:
  prompt='Language modeling is '
    compared=20/22  R2=0.9029  pearson=0.9613  MAE=0.0565  agree@0.5=1.000
  prompt='The quick brown fox '
    compared=19/21  R2=0.7846  pearson=0.8910  MAE=0.1058  agree@0.5=0.947
  prompt='def fibonacci(n):\n'
    compared=17/19  R2=0.6053  pearson=0.7945  MAE=0.1342  agree@0.5=0.882
  prompt='Hello world! This is a test of boundaries.\n'
    compared=42/44  R2=0.9049  pearson=0.9608  MAE=0.0554  agree@0.5=0.976

K=8192:
  prompt='Language modeling is '
    compared=20/22  R2=0.9735  pearson=0.9894  MAE=0.0260  agree@0.5=1.000
  prompt='The quick brown fox '
    compared=19/21  R2=0.8585  pearson=0.9268  MAE=0.0653  agree@0.5=0.947
  prompt='def fibonacci(n):\n'
    compared=17/19  R2=0.7209  pearson=0.8499  MAE=0.0899  agree@0.5=0.941
  prompt='Hello world! This is a test of boundaries.\n'
    compared=42/44  R2=0.9392  pearson=0.9753  MAE=0.0449  agree@0.5=1.000

K=16384:
  prompt='Language modeling is '
    compared=20/22  R2=0.9847  pearson=0.9935  MAE=0.0227  agree@0.5=1.000
  prompt='The quick brown fox '
    compared=19/21  R2=0.8527  pearson=0.9242  MAE=0.0601  agree@0.5=0.947
  prompt='def fibonacci(n):\n'
    compared=17/19  R2=0.7243  pearson=0.8546  MAE=0.0747  agree@0.5=0.941
  prompt='Hello world! This is a test of boundaries.\n'
    compared=42/44  R2=0.9471  pearson=0.9777  MAE=0.0389  agree@0.5=1.000

K=32768:
  prompt='Language modeling is '
    compared=20/22  R2=0.9901  pearson=0.9958  MAE=0.0186  agree@0.5=1.000
  prompt='The quick brown fox '
    compared=19/21  R2=0.8734  pearson=0.9356  MAE=0.0506  agree@0.5=0.947
  prompt='def fibonacci(n):\n'
    compared=17/19  R2=0.7303  pearson=0.8575  MAE=0.0756  agree@0.5=0.941
  prompt='Hello world! This is a test of boundaries.\n'
    compared=42/44  R2=0.9786  pearson=0.9910  MAE=0.0239  agree@0.5=1.000

Done.
(.venv) PS F:\Development\superintelligence> python secret_lab_ignore/blomo_port/lab.py --module 4
Loading Bolmo-1B on cpu (dtype=torch.float32)...
Loading weights: 100%|█| 263/263 [00:00<00:00, 2714.39it/s, Materializing param=model.n
Loaded. Parameters: 1,468,911,776

--- Module 4: Patch stats (Bolmo vs Adaptor) ---
Using K=16384, threshold=0.5

prompt='Language modeling is '
  bolmo:   PatchStats(n_bytes=21, n_pairs=20, boundary_rate=0.15, mean_bytes_per_patch=5.25, median_bytes_per_patch=5.5, max_patch=9)
  adaptor: PatchStats(n_bytes=21, n_pairs=20, boundary_rate=0.15, mean_bytes_per_patch=5.25, median_bytes_per_patch=5.5, max_patch=9)

prompt='The quick brown fox '
  bolmo:   PatchStats(n_bytes=20, n_pairs=19, boundary_rate=0.2631578947368421, mean_bytes_per_patch=3.3333333333333335, median_bytes_per_patch=3.0, max_patch=6)
  adaptor: PatchStats(n_bytes=20, n_pairs=19, boundary_rate=0.21052631578947367, mean_bytes_per_patch=4.0, median_bytes_per_patch=4.0, max_patch=6)

prompt='def fibonacci(n):\n'
  bolmo:   PatchStats(n_bytes=18, n_pairs=17, boundary_rate=0.23529411764705882, mean_bytes_per_patch=3.6, median_bytes_per_patch=3.0, max_patch=6)
  adaptor: PatchStats(n_bytes=18, n_pairs=17, boundary_rate=0.17647058823529413, mean_bytes_per_patch=4.5, median_bytes_per_patch=3.0, max_patch=10)

Done.
(.venv) PS F:\Development\superintelligence> python secret_lab_ignore/blomo_port/lab.py --module 5
Loading Bolmo-1B on cpu (dtype=torch.float32)...
Loading weights: 100%|█| 263/263 [00:00<00:00, 2586.38it/s, Materializing param=model.n
Loaded. Parameters: 1,468,911,776

--- Module 5: Porting suite (analysis + 512 token A/B + deterministic equivalence) ---  

[Module 5] Using K=16384, max_new_tokens=512
Adaptor key: '69eb4607b69f0909'

=== Prefill analysis: 'Language modeling is ' ===
  compared=20/22  R2=0.9847  pearson=0.9935  MAE=0.0227  agree@0.5=1.000
  expected sample mismatches ≈ 0.45 (2.27% per position)
  Patch stats (deterministic threshold=0.5):
    bolmo:   PatchStats(n_bytes=21, n_pairs=20, boundary_rate=0.15, mean_bytes_per_patch=5.25, median_bytes_per_patch=5.5, max_patch=9)
    adaptor: PatchStats(n_bytes=21, n_pairs=20, boundary_rate=0.15, mean_bytes_per_patch=5.25, median_bytes_per_patch=5.5, max_patch=9)
  Patch stats (sampled with shared U seed=123):
    bolmo:   PatchStats(n_bytes=21, n_pairs=20, boundary_rate=0.15, mean_bytes_per_patch=5.25, median_bytes_per_patch=5.5, max_patch=9)
    adaptor: PatchStats(n_bytes=21, n_pairs=20, boundary_rate=0.15, mean_bytes_per_patch=5.25, median_bytes_per_patch=5.5, max_patch=9)
    mismatch rate: 0.000

=== Prefill analysis: 'The quick brown fox ' ===
  compared=19/21  R2=0.8527  pearson=0.9242  MAE=0.0601  agree@0.5=0.947
  expected sample mismatches ≈ 1.14 (6.01% per position)
  Patch stats (deterministic threshold=0.5):
    bolmo:   PatchStats(n_bytes=20, n_pairs=19, boundary_rate=0.2631578947368421, mean_bytes_per_patch=3.3333333333333335, median_bytes_per_patch=3.0, max_patch=6)
    adaptor: PatchStats(n_bytes=20, n_pairs=19, boundary_rate=0.21052631578947367, mean_bytes_per_patch=4.0, median_bytes_per_patch=4.0, max_patch=6)
  Patch stats (sampled with shared U seed=123):
    bolmo:   PatchStats(n_bytes=20, n_pairs=19, boundary_rate=0.21052631578947367, mean_bytes_per_patch=4.0, median_bytes_per_patch=4.0, max_patch=6)
    adaptor: PatchStats(n_bytes=20, n_pairs=19, boundary_rate=0.21052631578947367, mean_bytes_per_patch=4.0, median_bytes_per_patch=4.0, max_patch=6)
    mismatch rate: 0.000

=== Prefill analysis: 'def fibonacci(n):\n' ===
  compared=17/19  R2=0.7243  pearson=0.8546  MAE=0.0747  agree@0.5=0.941
  expected sample mismatches ≈ 1.27 (7.47% per position)
  Patch stats (deterministic threshold=0.5):
    bolmo:   PatchStats(n_bytes=18, n_pairs=17, boundary_rate=0.23529411764705882, mean_bytes_per_patch=3.6, median_bytes_per_patch=3.0, max_patch=6)
    adaptor: PatchStats(n_bytes=18, n_pairs=17, boundary_rate=0.17647058823529413, mean_bytes_per_patch=4.5, median_bytes_per_patch=3.0, max_patch=10)
  Patch stats (sampled with shared U seed=123):
    bolmo:   PatchStats(n_bytes=18, n_pairs=17, boundary_rate=0.23529411764705882, mean_bytes_per_patch=3.6, median_bytes_per_patch=3.0, max_patch=6)
    adaptor: PatchStats(n_bytes=18, n_pairs=17, boundary_rate=0.17647058823529413, mean_bytes_per_patch=4.5, median_bytes_per_patch=3.0, max_patch=10)
    mismatch rate: 0.059

=== 512-token quality suite on prompt: 'Language modeling is ' ===

[A] Baseline (Bolmo, sampled boundaries)
  tokens=532 time=39.57s
  preview:
Language modeling is a fundamental task in natural language processing (NLP). It is a key component of machine translation, automatic speech recognition, and a variety of other applications. Traditional methods for language modeling typically require a large amount of labeled data, which is often not easily available. In this paper, we propose a novel method for language modeling that uses multitask learning. Our approach uses multiple tasks to learn a distribution over word sequences. We show empirically that the proposed model can effectively pe

[B] Patched (Adaptor, sampled boundaries) K=16384
  tokens=532 time=40.99s
  preview:
Language modeling is not strictly a machine learning technique, because it does not train a model that uses comparisons between words and concepts. Instead, it uses statistics to infer relationships between parts of speech. For example, the word “generate” is likely to occur in contexts where it refers to creating something. This kind of analysis can be used to predict the meaning of words in contexts that do not include the word that follows.\n\nSpeech is one of the most natural and intuitive ways to communicate, and it has been a popular topic

  A vs B token-id match: 40/532 = 0.075
  first divergence step: 0

[C] Baseline deterministic boundaries (Bolmo mask=p>0.5)
  tokens=532 time=39.36s
  preview:
Language modeling is a fundamental task in natural language processing (NLP). It is a key component of machine translation, automatic speech recognition, and a variety of other applications. Traditional methods for language modeling typically require a large amount of labeled data, which is often not easily available. In this paper, we propose a novel method for language modeling that uses multitask learning. Our approach uses multiple tasks to learn a distribution over word sequences. We show empirically that the proposed model can effectively pe

[D] Patched deterministic boundaries (Adaptor mask=p>0.5) K=16384
  tokens=532 time=39.82s
  preview:
Language modeling is a fundamental task in natural language processing (NLP). It is a key component of machine translation, automatic speech recognition, and a variety of other applications. Traditional methods for language modeling typically require a large amount of labeled data, which is often not easily available. In this paper, we propose a novel method for language modeling that uses multitask learning. Our approach uses multiple tasks to learn a distribution over word sequences. We show empirically that the proposed model can effectively pe

  C vs D token-id match: 532/532 = 1.000
  first divergence step: 532

  A vs C token-id match (sampling vs deterministic boundaries): 532/532 = 1.000
  first divergence step: 532

Done.
(.venv) PS F:\Development\superintelligence> python secret_lab_ignore/blomo_port/lab.py --module 6
Loading Bolmo-1B on cpu (dtype=torch.float32)...
Loading weights: 100%|█| 263/263 [00:00<00:00, 2424.96it/s, Materializing param=model.n
Loaded. Parameters: 1,468,911,776

--- Module 6: Prefill fast port (compute removal) ---

[Module 6] Prefill fast port + compute removal proof
  prompt='Language modeling is '
  K=16384
  max_new_tokens=512

Baseline deterministic:
  tokens=532 time=40.69s  boundary_predictor_calls=2
  preview:
Language modeling is a fundamental task in natural language processing (NLP). It is a key component of machine translation, automatic speech recognition, and a variety of other applications. Traditional methods for language modeling typically require a large amount of labeled data, which is often not easily available. In this paper, we propose a novel method for language modeling that uses multitask learning. Our approach uses multiple tasks to learn a distribution over word sequences. We show empirically that the proposed model can effectively pe

Patched deterministic (prefill fast):
  tokens=532 time=39.95s  boundary_predictor_calls=1
  preview:
Language modeling is a fundamental task in natural language processing (NLP). It is a key component of machine translation, automatic speech recognition, and a variety of other applications. Traditional methods for language modeling typically require a large amount of labeled data, which is often not easily available. In this paper, we propose a novel method for language modeling that uses multitask learning. Our approach uses multiple tasks to learn a distribution over word sequences. We show empirically that the proposed model can effectively pe

Token-id match: 532/532 = 1.000
First divergence at step: 532

Compute removal: boundary_predictor_module.forward calls reduced.

Done.
(.venv) PS F:\Development\superintelligence> 